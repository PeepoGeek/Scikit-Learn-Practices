{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accd4d1c",
   "metadata": {},
   "source": [
    "# Text Classification with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0ef2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "%pylab inline\n",
    "\n",
    "news = fetch_20newsgroups(subset=\"all\")\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0088f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      " 10\n"
     ]
    }
   ],
   "source": [
    "print(news.data[0], news.target[0]) # the data holds a list of text contents, instead of a numpy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c48e324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846 <class 'numpy.ndarray'> <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(news.data), type(news.target),\n",
    "type(news.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaeb050a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14134 4712\n"
     ]
    }
   ],
   "source": [
    "#converting our text-based dataset to a numeric dataset\n",
    "\n",
    "SPLIT_PERC = 0.75 #Spliting data for train and test \n",
    "\n",
    "split_size = int(len(news.data)*SPLIT_PERC) \n",
    "\n",
    "X_train = news.data[:split_size]\n",
    "\n",
    "X_test = news.data[split_size:]\n",
    "\n",
    "y_train = news.target[:split_size]\n",
    "\n",
    "y_test = news.target[split_size:]\n",
    "\n",
    "\n",
    "print(len(X_train),len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b91dbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training naive bayes classifier with 3 different class transform\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "\n",
    "clf_1 = Pipeline([(\"vect\", CountVectorizer()), (\"clf\", MultinomialNB()),])\n",
    "\n",
    "clf_2 = Pipeline([(\"vect\", TfidfVectorizer()), (\"clf\", MultinomialNB()),])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26f30da9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85782493 0.85725657 0.84664367 0.85911382 0.8458477 ]\n",
      "Mean score: 0.853337340146793 +/- 0.0029134723097208348\n",
      "[0.84482759 0.85990979 0.84558238 0.85990979 0.84213319]\n",
      "Mean score: 0.8504725482840962 +/- 0.003895171759717566\n"
     ]
    }
   ],
   "source": [
    "#defining a function that takes a classifier and performs the K-fold cross-validation over the specified X and y values\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "\n",
    "def evaluate_cross_validation(clf, X, y, K):\n",
    "    \n",
    "    # create a k-fold croos validation iterator of k=5 folds\n",
    "    cv = KFold(shuffle=True, random_state=0)\n",
    "    \n",
    "    # by default the score used is the one returned by score >>> method of the estimator (accuracy)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv)\n",
    "    \n",
    "    print(scores)\n",
    "    print(f\"Mean score: {np.mean(scores)} +/- {sem(scores)}\")\n",
    "\n",
    "\n",
    "clfs = [clf_1, clf_2]\n",
    "\n",
    "for clf in clfs:\n",
    "    \n",
    "    evaluate_cross_validation(clf, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3093aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_4 = Pipeline([('vect', TfidfVectorizer(token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\")),('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06192215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86100796 0.8718493  0.86203237 0.87291059 0.8588485 ]\n",
      "Mean score: 0.8653297422150406 +/- 0.002928572778614428\n"
     ]
    }
   ],
   "source": [
    "evaluate_cross_validation(clf_4, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56a38d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"using stop_words: this argument allows us to pass a list of words we do not want to take into account,\n",
    "such as too frequent words, or words we do not a priori expect to provide information about the particular topic\"\"\"\n",
    "\n",
    "def get_stop_words():\n",
    "    \n",
    "    result = set()\n",
    "    \n",
    "    for line in open(\"stopwords_en.txt\",\"r\").readlines(): # In this case iÂ´m using just a place holder for the txt archive\n",
    "        \n",
    "        result.add(line.strip())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2f5e549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86100796 0.8718493  0.86203237 0.87291059 0.8588485 ]\n",
      "Mean score: 0.8653297422150406 +/- 0.002928572778614428\n"
     ]
    }
   ],
   "source": [
    "clf_5 = Pipeline([(\"vect\", TfidfVectorizer(stop_words= get_stop_words(), token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\" )), (\"clf\", MultinomialNB())])\n",
    "\n",
    "evaluate_cross_validation(clf_5, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2fb1c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9198939  0.919342   0.91748474 0.92491377 0.91775007]\n",
      "Mean score: 0.9198768960520454 +/- 0.0013398190194147679\n",
      "[0.90742706 0.91138233 0.90342266 0.91483152 0.90368798]\n",
      "Mean score: 0.9081503089914722 +/- 0.0022121334442564903\n",
      "[0.89230769 0.89546299 0.88882993 0.89572831 0.88644203]\n",
      "Mean score: 0.8917541890319816 +/- 0.0018251788140663436\n",
      "[0.86976127 0.88033961 0.87052269 0.87927832 0.86786946]\n",
      "Mean score: 0.8735542710918965 +/- 0.002595188239430988\n"
     ]
    }
   ],
   "source": [
    "\"experimenting with some alpha parameter\"\n",
    "\n",
    "alph = [0.01,0.1,0.3,0.7]\n",
    "\n",
    "for i in alph:\n",
    "    \n",
    "    clf_7 = Pipeline([(\"vect\", TfidfVectorizer(stop_words= get_stop_words(),\n",
    "                            token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\" )),\n",
    "                      (\"clf\", MultinomialNB(alpha = i))])\n",
    "\n",
    "    evaluate_cross_validation(clf_7, news.data, news.target, 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45da4861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.9966746851563606 \n",
      "Accuracy on testing set: 0.9159592529711376 \n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       216\n",
      "           1       0.83      0.84      0.83       246\n",
      "           2       0.91      0.83      0.87       274\n",
      "           3       0.81      0.86      0.83       235\n",
      "           4       0.87      0.90      0.89       231\n",
      "           5       0.89      0.91      0.90       225\n",
      "           6       0.88      0.80      0.84       248\n",
      "           7       0.93      0.93      0.93       275\n",
      "           8       0.96      0.98      0.97       226\n",
      "           9       0.97      0.94      0.96       250\n",
      "          10       0.97      1.00      0.98       257\n",
      "          11       0.96      0.98      0.97       261\n",
      "          12       0.90      0.91      0.91       216\n",
      "          13       0.94      0.96      0.95       257\n",
      "          14       0.94      0.96      0.95       246\n",
      "          15       0.90      0.97      0.93       234\n",
      "          16       0.90      0.97      0.94       218\n",
      "          17       0.97      0.99      0.98       236\n",
      "          18       0.95      0.90      0.93       213\n",
      "          19       0.88      0.76      0.82       148\n",
      "\n",
      "    accuracy                           0.92      4712\n",
      "   macro avg       0.91      0.91      0.91      4712\n",
      "weighted avg       0.92      0.92      0.92      4712\n",
      "\n",
      "Confusion Matrix:[[190   0   0   0   1   0   0   0   0   1   0   0   0   1   0  10   2   0\n",
      "    0  11]\n",
      " [  0 207   5   4   3  13   4   0   0   0   0   1   3   2   3   0   0   1\n",
      "    0   0]\n",
      " [  0  12 228  23   1   5   1   0   1   0   0   0   0   0   1   0   1   0\n",
      "    1   0]\n",
      " [  0   6   7 201  10   3   4   0   0   0   0   0   3   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   2   3   5 208   1   4   0   0   0   2   0   5   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0  10   2   1   1 205   0   1   1   0   0   0   0   2   1   0   0   1\n",
      "    0   0]\n",
      " [  0   2   3   9   6   0 198  14   0   2   1   2   6   2   2   0   0   1\n",
      "    0   0]\n",
      " [  0   3   0   1   1   0   7 255   4   1   0   0   0   1   0   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   1   2 221   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   1   0   2 236   5   0   1   2   0   1   1   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0 256   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0 255   0   1   0   0   3   0\n",
      "    1   0]\n",
      " [  0   1   0   1   5   1   3   1   0   2   1   1 197   2   1   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   1   1   0   0   0   0   0   0   2   1 246   3   0   1   0\n",
      "    0   1]\n",
      " [  0   4   0   0   1   0   1   0   0   0   0   0   0   1 236   0   1   0\n",
      "    1   1]\n",
      " [  1   0   1   2   0   0   0   1   0   0   0   1   1   0   1 226   0   0\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   1   0   1   0   0   1   0   0   0   0 212   0\n",
      "    2   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 234\n",
      "    1   0]\n",
      " [  1   0   0   0   0   0   1   0   0   0   0   2   1   1   0   1   7   4\n",
      "  192   3]\n",
      " [  9   0   0   0   0   1   0   0   0   1   0   0   0   0   0  14   5   1\n",
      "    4 113]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Now, will define a helper function that will train the model in the entire training set and evaluate the accuracy in \n",
    "the training and in the testing sets. It will also print a classification report (precision and recall on every class)\n",
    "and the corresponding confusion matrix:\"\"\" \n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "clf_8 = Pipeline([(\"vect\", TfidfVectorizer(stop_words= get_stop_words(),\n",
    "                                           token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\" )), (\"clf\", MultinomialNB(alpha = 0.01))])\n",
    "\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Accuracy on training set: {clf.score(X_train, y_train)} \")\n",
    "    \n",
    "    print(f\"Accuracy on testing set: {clf.score(X_test, y_test)} \")\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    \n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    \n",
    "    print(f\"Confusion Matrix:{metrics.confusion_matrix(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "train_and_evaluate(clf_8, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0e5257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
